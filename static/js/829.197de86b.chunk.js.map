{"version":3,"file":"static/js/829.197de86b.chunk.js","mappings":"yMAGA,MAuCA,EAvCsB,IAYf,IAZgB,YACrBA,EADqB,OAErBC,EAFqB,UAGrBC,EAHqB,WAIrBC,EAJqB,eAKrBC,GAOI,EACJ,MAAM,MAAEC,EAAF,OAASC,GAAWN,EACpBO,GAAUC,EAAAA,EAAAA,IAAWP,GAEtBE,GAMLI,EAAQE,OAGRF,EAAQG,UAAUV,EAAa,EAAG,GAE9BI,EAAiB,IACnBG,EAAQI,OAAU,QAAOP,SAG3BQ,EAAAA,EAAAA,IAAoBL,EAASJ,EAAY,kBAAmBE,EAAOC,GACnEC,EAAQI,OAAS,QAEjBC,EAAAA,EAAAA,IAAoBL,EAASL,EAAW,mBAAoBG,EAAOC,GAEnEC,EAAQM,WAnBNN,EAAQG,UAAUV,EAAa,EAAG,I,sCChBtC,IAAIc,EAAoB,GAEjB,MAAMC,EAAyB,KACpCD,EAAoB,IAaTE,EAAmBC,UAC9B,MAKMC,QAAgCC,EAAAA,GACpCC,EANsB,CAAEC,EAAG,EAAGC,EAAG,EAAGC,EAAG,EAAGC,EAAG,GACvB,CAAEH,EAAG,EAAGC,EAAG,EAAGC,EAAG,EAAGC,EAAG,MAC3B,EACQ,KAUtB,MAAEnB,EAAF,OAASC,GAAWY,EACpBjB,EAzB6B,EAACwB,EAAIpB,EAAOC,KAC/C,MAAMoB,EAAO,GAAED,KAAMpB,KAASC,IAM9B,OAJKQ,EAAkBY,KACrBZ,EAAkBY,IAAOC,EAAAA,EAAAA,IAAsBtB,EAAOC,IAGjDQ,EAAkBY,IAkBVE,CAA6B,cAAevB,EAAOC,GAIlE,OAFAuB,EAAAA,EAAAA,IAAwBX,EAAyBjB,GAE1CA,EAAO6B,yBCxBhB,EAZyBb,MAAOc,EAAP,KAAsD,IAArB,YAAEC,GAAkB,EAC5E,MAAMZ,QAAqBW,EAAUE,cAAcD,GAEnD,GAAIE,MAAMC,QAAQf,IAAyC,IAAxBA,EAAagB,OAC9C,OAKF,OAFmBpB,EAAiBI,ICqBtC,EAzBoB,KAClB,MAAMiB,EAAgB,GAQhBC,EAAgB,CAACC,EAAcC,KACnCH,EAAME,GAAQC,GAOhB,MAAO,CACLC,cAZqBF,GACdF,EAAME,GAYbG,SAhBe,IACRL,EAgBPC,gBACAK,UARgB,IAAiC,IAAhC,eAAEC,GAA6B,EAChDN,EAAc,iBAAkBM,OCT9B,SAAEF,EAAF,UAAYC,EAAZ,cAAuBL,GAAkBO,IAC/C,IAAId,EAEJ,MAAMe,EAAQ3B,EAAAA,GAAAA,4BAER4B,EAAgB9B,UAAoE,IAA7D,eAAE2B,GAA0D,EACvF,MAAMI,EAAkB,CACtBC,QAAS,OACTC,UAAWN,GAGbb,QAAkBZ,EAAAA,GAA2C2B,EAAOE,IA0BtE,EAvBa,IAA8D,IAA7D,eAAEJ,GAA0D,EAMxE,OALAD,EAAU,CACRC,mBAEF7B,IAEOgC,EAAc,CAAEH,oBAiBzB,EAdsBZ,GACbmB,EAAiBpB,EAAW,CACjCC,gBAYJ,EARqB,IAA8D,IAA7D,eAAEY,GAA0D,EAKhF,OAJAN,EAAc,iBAAkBM,GAEhC7B,IAEOgC,EAAc,CAAEH,oBC4IzB,EAjL4D,IAIrD,IAJsD,oBAC3DQ,EAD2D,oBAE3DC,EAF2D,qBAG3DC,GACI,EACJ,MAAMC,GAAWC,EAAAA,EAAAA,KACXC,EAAmB,IAAIC,EAAAA,EAC7B,IACIC,EACA3D,EACA4D,EAHAC,GAAW,EAYf,IAAIC,GAA8B,EAClC,MAaMC,EAAuB,IAAqD,IAApD,eAAE3D,GAAiD,EAC/E,MAAM,MAAEC,EAAF,OAASC,GAAWN,EACpBgE,GAAerC,EAAAA,EAAAA,IAAsBtB,EAAOC,GAClD,IAAI2D,EAGJ,OAAQ5D,GACN,KAAK,IACH4D,EAAkBb,EAClB,MACF,KAAK,KACHa,EAAkBZ,EAClB,MACF,KAAK,KACHY,EAAkBX,EAItB,IACInD,EADA+D,GAAoBC,EAAAA,EAAAA,IAAmB,CAAEC,MAAOpE,EAAaC,OAAQ+D,IAGzET,EAASc,OACTR,GAAW,EAEX,MAAMS,EAAwBrD,UAE5BsC,EAASgB,QACTT,GAA8B,EAE1BD,IACF1D,QAAmB8C,EAAqBiB,IAI1CX,EAASiB,MAETV,GAA8B,EAG1BD,IACFF,EAAiCc,sBAAsBH,KAIrDI,EAAmB,KACvBR,GAAoBC,EAAAA,EAAAA,IAAmB,CAAEC,MAAOpE,EAAaC,OAAQ+D,IAErEW,EAAc,CACZxE,aACAC,iBACAJ,cACAE,UAAW+D,EACXhE,OAAQ2D,KAIZU,IAAwBM,MAAK,KAC3BnB,EAAiBoB,WACjBpB,EAAiBqB,IAAIJ,EAAkB,QAIrCK,EAAQ,IAQP,IARQ,YACbC,EADa,eAEbpC,EAFa,eAGbxC,GAKI,EACJ,OAAO6C,EACC,CACJL,mBAEDgC,MAAK,IAhGWI,KACZC,EAAAA,EAAAA,GAAmBD,GAAaJ,MAAMM,IAC3ClF,EAAckF,EAEPlF,KA6FEmF,CAAYH,KAEpBJ,MAAK,KACJ,MAAM,MAAEvE,EAAF,OAASC,GAAWN,EAE1B4D,GAAewB,EAAAA,EAAAA,IAAa/E,EAAOC,GAEnCyD,EAAqB,CAAE3D,mBAIvB,OAF0BwD,EAAayB,oBAKvCC,EAAsB,KAC1BzB,GAAW,EACX0B,OAAOC,qBAAqB7B,GAC5BF,EAAiBgC,aACjBlC,EAASmC,QA1GF,IAAIC,SAAeC,IACxB,MAAMC,EAAQ,MACwB,IAAhC/B,EACF8B,IAEAE,WAAWD,EAAO,MAItBA,QAqGEE,EAAO,IACJT,IAAsBV,MAAK,KAC5B5E,IACFA,EAAYgG,UAAY,SAwC9B,MAAO,CAAEjB,QAAOkB,QAlBA,IAQT,IARU,YACfjB,EADe,eAEfpC,EAFe,eAGfxC,GAKI,EACJ,OAAO2F,IAAOnB,MAAK,IACVG,EAAM,CACXC,cACApC,iBACAxC,sBAKmB8F,aAnCJ,IAMd,IANe,eACpBtD,EADoB,eAEpBxC,GAII,EACJ,OAAOkF,IACJV,MAAK,IACG3B,EAAqB,CAC1BL,qBAGHgC,MAAK,IACGb,EAAqB,CAAE3D,sBAqBG2F,U,2FCpLlC,MAAMX,EAAe,CAAC/E,EAAeC,KAC1C,MAAML,EAASkG,SAASC,cAAc,UAKtC,OAHAnG,EAAOI,MAAQA,EACfJ,EAAOK,OAASA,EAETL,GAGIO,EAAa,SACxBP,GAYO,IAXP,KACEoG,EAAO,KADT,sBAEEC,EAFF,yBAGEC,EAHF,MAIEC,GAAQ,GAOJ,uDADF,GAEJ,MAAMjG,EAAUN,EAAOO,WAAW6F,EAAM,CACtCG,QACAC,gBAAgB,EAChBC,oBAAoB,IAGlBJ,IACF/F,EAAQoG,uBAAwB,EAChCpG,EAAQ+F,sBAAwBA,GAG9BC,IACFhG,EAAQgG,yBAA2BA,GAKrC,OAFwBhG,GAKboB,EAAwB,CAACtB,EAAeC,IAC3B,IAAIsG,gBAAgBvG,EAAOC,GA2B/CuG,EAAiBzC,IACrB,MAAM,OAAE9D,EAAF,MAAUD,GAAU+D,EAE1B,MAAO,CAAE9D,SAAQD,UAGNwB,EAA0B,CAACuC,EAAkBnE,KACxCO,EAAWP,GAEnB6G,aAAa1C,EAAO,EAAG,IAGpB2C,EAAsB,SACjC3C,EACAnE,GAkBI,IAjBJ,EACE+G,EAAI,EADN,EAEEC,EAAI,EAFN,MAGE5G,EAHF,OAIEC,EAJF,sBAKEgG,EALF,MAMEE,EANF,yBAOED,GAUC,uDADC,GAEJ,MAAMW,EAAaL,EAAczC,GAC3B+C,EAAc9G,GAAS6G,EAAW7G,MAClC+G,EAAe9G,GAAU4G,EAAW5G,OACpCC,EAAUC,EAAWP,EAAQ,CAAEqG,wBAAuBE,QAAOD,6BAEnEhG,EAAQG,UAAU0D,EAAO4C,EAAGC,EAAGE,EAAaC,IAgCjCxG,EAAsB,CACjCL,EACA6D,EACAiD,EACAC,EACAC,KAEAhH,EAAQgG,yBAA2Bc,EAEnC,MAAM,MAAEhH,EAAF,OAASC,GAAW8D,EAE1B7D,EAAQG,UACN0D,EACA,EACA,EAEA/D,EACAC,EACA,EACA,EACAgH,EACAC,IAeSpD,EAAqB,IAM3B,IAN4B,OACjClE,EADiC,MAEjCmE,GAII,EAGJ,OAFA2C,EAAoB3C,EAAOnE,GAEpBA,EAAO6B,0B,oEC1LhB,MAkCA,EAlCuB,KACrB,IAAI0F,EACAC,GAAY,EACZC,GAAU,EA4Bd,MAAO,CAAErD,KA3BI,KACXoD,GAAY,EACZC,GAAU,EACVF,EAAQ,IAAIG,KACZH,EAAMI,UAAU,GAEhBzB,SAAS0B,KAAKC,YAAYN,EAAMO,MAqBnBxD,MAnBD,KACRiD,GAASE,IAAYD,IACvBC,GAAU,EACVD,GAAY,EACZD,EAAMjD,UAeYC,IAZV,KACNgD,GAASC,IAAcC,IACzBA,GAAU,EACVD,GAAY,EACZD,EAAMhD,QAQiBkB,MALb,KACZS,SAAS0B,KAAKG,YAAYR,EAAMO,KAChCP,OAAQS,M,6CC9BZ,MAeA,EAf4BjD,IAC1B,MAAMkD,EAAe/B,SAASC,cAAc,SAI5C,OAFA8B,EAAalC,UAAYhB,EAElB,IAAIW,SAASC,IAClBsC,EAAaC,iBAAmB,KAC9BD,EAAa7H,MAAQ6H,EAAaE,WAClCF,EAAa5H,OAAS4H,EAAaG,YACnCH,EAAaI,OACb1C,EAAQsC,S","sources":["createVideoProcessor/VideoProcessors/TensorFlow/drawImageMask.ts","createVideoProcessor/VideoProcessors/TensorFlow/runtime/render.ts","createVideoProcessor/VideoProcessors/TensorFlow/runtime/bodySegmentation.ts","createVideoProcessor/VideoProcessors/TensorFlow/runtime/state.ts","createVideoProcessor/VideoProcessors/TensorFlow/runtime/index.ts","createVideoProcessor/VideoProcessors/TensorFlow/index.ts","utils/canvas.ts","utils/createFpsMeter.ts","utils/mediaStreamToVideo.ts"],"sourcesContent":["import { getContext, drawWithCompositing } from '../../../utils/canvas';\nimport type { TCanvas } from '../../../utils/canvas';\n\nconst drawImageMask = ({\n  videoSource,\n  canvas,\n  imageMask,\n  personMask,\n  edgeBlurAmount,\n}: {\n  videoSource: HTMLVideoElement;\n  canvas: TCanvas;\n  imageMask: HTMLImageElement;\n  personMask?: ImageBitmap;\n  edgeBlurAmount: number;\n}) => {\n  const { width, height } = videoSource;\n  const context = getContext(canvas);\n\n  if (!personMask) {\n    context.drawImage(videoSource, 0, 0);\n\n    return;\n  }\n\n  context.save();\n\n  // render original image\n  context.drawImage(videoSource, 0, 0);\n\n  if (edgeBlurAmount > 0) {\n    context.filter = `blur(${edgeBlurAmount}px)`;\n  }\n\n  drawWithCompositing(context, personMask, 'destination-out', width, height);\n  context.filter = 'none';\n\n  drawWithCompositing(context, imageMask, 'destination-over', width, height);\n\n  context.restore();\n};\n\nexport default drawImageMask;\n","import * as tensorflowBodySegmentation from '@tensorflow-models/body-segmentation';\nimport type { Segmentation } from '@tensorflow-models/body-segmentation/dist/shared/calculators/interfaces/common_interfaces';\nimport { renderImageDataToCanvas, createOffScreenCanvas } from '../../../../utils/canvas';\n\nlet offScreenCanvases = {};\n\nexport const resetOffScreenCanvases = () => {\n  offScreenCanvases = {};\n};\n\nconst ensureOffscreenCanvasCreated = (id, width, height) => {\n  const key = `${id}_${width}_${height}`;\n\n  if (!offScreenCanvases[key]) {\n    offScreenCanvases[key] = createOffScreenCanvas(width, height);\n  }\n\n  return offScreenCanvases[key];\n};\n\nexport const createPersonMask = async (segmentation: Segmentation[]) => {\n  const foregroundColor = { r: 0, g: 0, b: 0, a: 0 };\n  const backgroundColor = { r: 0, g: 0, b: 0, a: 255 };\n  const drawContour = true;\n  const foregroundThreshold = 0.6;\n\n  const backgroundDarkeningMask = await tensorflowBodySegmentation.toBinaryMask(\n    segmentation,\n    foregroundColor,\n    backgroundColor,\n    drawContour,\n    foregroundThreshold\n  );\n\n  const { width, height } = backgroundDarkeningMask;\n  const canvas = ensureOffscreenCanvasCreated('blurredMask', width, height);\n\n  renderImageDataToCanvas(backgroundDarkeningMask, canvas);\n\n  return canvas.transferToImageBitmap();\n};\n","import type { BodySegmenter } from '@tensorflow-models/body-segmentation/dist/body_segmenter';\nimport { createPersonMask } from './render';\n\nconst bodySegmentation = async (segmenter: BodySegmenter, { imageBitmap }) => {\n  const segmentation = await segmenter.segmentPeople(imageBitmap);\n\n  if (Array.isArray(segmentation) && segmentation.length === 0) {\n    return undefined;\n  }\n\n  const personMask = createPersonMask(segmentation);\n\n  return personMask;\n};\n\nexport default bodySegmentation;\n","import type { TModelSelection } from '../../../../typings';\n\ntype TState = {\n  modelSelection?: TModelSelection;\n};\n\nconst createState = () => {\n  const state: TState = {};\n\n  const getState = (): TState => {\n    return state;\n  };\n  const getStateValue = (name: string): string | undefined => {\n    return state[name];\n  };\n  const setStateValue = (name: string, value?: string) => {\n    state[name] = value;\n  };\n\n  const initState = ({ modelSelection }: TState) => {\n    setStateValue('modelSelection', modelSelection);\n  };\n\n  return {\n    getStateValue,\n    getState,\n    setStateValue,\n    initState,\n  };\n};\n\nexport default createState;\n","import '@tensorflow/tfjs-core';\nimport '@tensorflow/tfjs-backend-webgl';\nimport * as tensorflowBodySegmentation from '@tensorflow-models/body-segmentation';\nimport type { BodySegmenter } from '@tensorflow-models/body-segmentation/dist/body_segmenter';\nimport '@tensorflow/tfjs-converter';\nimport type { TModelSelection } from '../../../../typings';\n// import '@mediapipe/selfie_segmentation';\nimport { resetOffScreenCanvases } from './render';\nimport bodySegmentation from './bodySegmentation';\nimport createState from './state';\n\nconst { getState, initState, setStateValue } = createState();\nlet segmenter: BodySegmenter;\n\nconst model = tensorflowBodySegmentation.SupportedModels.MediaPipeSelfieSegmentation; // or 'BodyPix'|| MediaPipeSelfieSegmentation\n\nconst loadSegmenter = async ({ modelSelection }: { modelSelection: TModelSelection }) => {\n  const segmenterConfig = {\n    runtime: 'tfjs' as const, // or 'tfjs' mediapipe\n    modelType: modelSelection, // or 'landscape'\n  };\n\n  segmenter = await tensorflowBodySegmentation.createSegmenter(model, segmenterConfig);\n};\n\nconst init = ({ modelSelection }: { modelSelection: TModelSelection }) => {\n  initState({\n    modelSelection,\n  });\n  resetOffScreenCanvases();\n\n  return loadSegmenter({ modelSelection });\n};\n\nconst processVideo = (imageBitmap) => {\n  return bodySegmentation(segmenter, {\n    imageBitmap,\n  });\n};\n\nconst changeParams = ({ modelSelection }: { modelSelection: TModelSelection }) => {\n  setStateValue('modelSelection', modelSelection);\n\n  resetOffScreenCanvases();\n\n  return loadSegmenter({ modelSelection });\n};\n\nexport default { init, processVideo, changeParams };\n","import AnimationRequest from 'request-animation-runner';\nimport type { TResolveProcessVideo, TModelSelection } from '../../../typings';\nimport createFpsMeter from '../../../utils/createFpsMeter';\nimport mediaStreamToVideo from '../../../utils/mediaStreamToVideo';\nimport { createCanvas, createOffScreenCanvas, imageToImageBitmap } from '../../../utils/canvas';\nimport drawImageMask from './drawImageMask';\nimport runtime from './runtime';\n\nconst resolveProcessVideoTensorFlow: TResolveProcessVideo = ({\n  imageBitmapMask360p,\n  imageBitmapMask720p,\n  imageBitmapMask1080p,\n}) => {\n  const fpsMeter = createFpsMeter();\n  const animationRequest = new AnimationRequest();\n  let isActive = false;\n  let requestIDBodySegmentationFrame: number;\n  let videoSource: HTMLVideoElement;\n  let canvasTarget: HTMLCanvasElement;\n\n  const createVideo = (mediaStream: MediaStream) => {\n    return mediaStreamToVideo(mediaStream).then((video) => {\n      videoSource = video;\n\n      return videoSource;\n    });\n  };\n  let isInProgressVideoProcessing = false;\n  const checkEndProgressVideoProcessing = () => {\n    return new Promise<void>((resolve) => {\n      const check = () => {\n        if (isInProgressVideoProcessing === false) {\n          resolve();\n        } else {\n          setTimeout(check, 100);\n        }\n      };\n\n      check();\n    });\n  };\n  const startVideoProcessing = ({ edgeBlurAmount }: { edgeBlurAmount: number }) => {\n    const { width, height } = videoSource;\n    const canvasSource = createOffScreenCanvas(width, height);\n    let imageBitmapMask: HTMLImageElement;\n\n    // eslint-disable-next-line default-case\n    switch (width) {\n      case 640:\n        imageBitmapMask = imageBitmapMask360p;\n        break;\n      case 1280:\n        imageBitmapMask = imageBitmapMask720p;\n        break;\n      case 1920:\n        imageBitmapMask = imageBitmapMask1080p;\n        break;\n    }\n\n    let imageBitmapSource = imageToImageBitmap({ image: videoSource, canvas: canvasSource });\n    let personMask: ImageBitmap;\n\n    fpsMeter.init();\n    isActive = true;\n\n    const bodySegmentationFrame = async () => {\n      // Begin monitoring code for frames per second\n      fpsMeter.begin();\n      isInProgressVideoProcessing = true;\n\n      if (isActive) {\n        personMask = await runtime.processVideo(imageBitmapSource);\n      }\n\n      // End monitoring code for frames per second\n      fpsMeter.end();\n\n      isInProgressVideoProcessing = false;\n\n      // for check after async\n      if (isActive) {\n        requestIDBodySegmentationFrame = requestAnimationFrame(bodySegmentationFrame);\n      }\n    };\n\n    const targetVideoFrame = () => {\n      imageBitmapSource = imageToImageBitmap({ image: videoSource, canvas: canvasSource });\n\n      drawImageMask({\n        personMask,\n        edgeBlurAmount,\n        videoSource,\n        imageMask: imageBitmapMask,\n        canvas: canvasTarget,\n      });\n    };\n\n    bodySegmentationFrame().then(() => {\n      animationRequest.activate();\n      animationRequest.run(targetVideoFrame, 24);\n    });\n  };\n\n  const start = ({\n    mediaStream,\n    modelSelection,\n    edgeBlurAmount,\n  }: {\n    mediaStream: MediaStream;\n    modelSelection: TModelSelection;\n    edgeBlurAmount: number;\n  }) => {\n    return runtime\n      .init({\n        modelSelection,\n      })\n      .then(() => {\n        return createVideo(mediaStream);\n      })\n      .then(() => {\n        const { width, height } = videoSource;\n\n        canvasTarget = createCanvas(width, height);\n\n        startVideoProcessing({ edgeBlurAmount });\n\n        const mediaStreamOutput = canvasTarget.captureStream();\n\n        return mediaStreamOutput;\n      });\n  };\n  const stopVideoProcessing = () => {\n    isActive = false;\n    window.cancelAnimationFrame(requestIDBodySegmentationFrame);\n    animationRequest.deactivate();\n    fpsMeter.reset();\n\n    return checkEndProgressVideoProcessing();\n  };\n  const stop = () => {\n    return stopVideoProcessing().then(() => {\n      if (videoSource) {\n        videoSource.srcObject = null;\n      }\n    });\n  };\n\n  const changeParams = ({\n    modelSelection,\n    edgeBlurAmount,\n  }: {\n    modelSelection: TModelSelection;\n    edgeBlurAmount: number;\n  }) => {\n    return stopVideoProcessing()\n      .then(() => {\n        return runtime.changeParams({\n          modelSelection,\n        });\n      })\n      .then(() => {\n        return startVideoProcessing({ edgeBlurAmount });\n      });\n  };\n  const restart = ({\n    mediaStream,\n    modelSelection,\n    edgeBlurAmount,\n  }: {\n    mediaStream: MediaStream;\n    modelSelection: TModelSelection;\n    edgeBlurAmount: number;\n  }) => {\n    return stop().then(() => {\n      return start({\n        mediaStream,\n        modelSelection,\n        edgeBlurAmount,\n      });\n    });\n  };\n\n  return { start, restart, changeParams, stop };\n};\n\nexport default resolveProcessVideoTensorFlow;\n","export type TCanvas = HTMLCanvasElement | OffscreenCanvas;\n\nexport const createCanvas = (width: number, height: number): HTMLCanvasElement => {\n  const canvas = document.createElement('canvas');\n\n  canvas.width = width;\n  canvas.height = height;\n\n  return canvas;\n};\n\nexport const getContext = <T = CanvasRenderingContext2D>(\n  canvas: TCanvas,\n  {\n    type = '2d',\n    imageSmoothingQuality,\n    globalCompositeOperation,\n    alpha = false,\n  }: {\n    type?: '2d';\n    imageSmoothingQuality?: ImageSmoothingQuality;\n    globalCompositeOperation?: GlobalCompositeOperation;\n    alpha?: boolean;\n  } = {}\n): T => {\n  const context = canvas.getContext(type, {\n    alpha,\n    desynchronized: true,\n    willReadFrequently: true,\n  }) as CanvasRenderingContext2D;\n\n  if (imageSmoothingQuality) {\n    context.imageSmoothingEnabled = true;\n    context.imageSmoothingQuality = imageSmoothingQuality;\n  }\n\n  if (globalCompositeOperation) {\n    context.globalCompositeOperation = globalCompositeOperation;\n  }\n\n  const contextReturned = context as unknown as T;\n\n  return contextReturned;\n};\n\nexport const createOffScreenCanvas = (width: number, height: number): OffscreenCanvas => {\n  const offScreenCanvas = new OffscreenCanvas(width, height);\n\n  return offScreenCanvas;\n};\n\nexport const fill = (\n  canvas: TCanvas,\n  {\n    x = 0,\n    y = 0,\n    width,\n    height,\n    color = '#202020',\n  }: {\n    x?: number;\n    y?: number;\n    width: number;\n    height: number;\n    color?: string;\n  }\n) => {\n  const context = getContext(canvas);\n\n  context.fillStyle = color;\n  context.fillRect(x, y, width, height);\n};\n\nconst getImageSizes = (image: CanvasImageSource | ImageBitmap) => {\n  const { height, width } = image as { width: number; height: number };\n\n  return { height, width };\n};\n\nexport const renderImageDataToCanvas = (image: ImageData, canvas) => {\n  const context = getContext(canvas);\n\n  context.putImageData(image, 0, 0);\n};\n\nexport const renderImageToCanvas = (\n  image: CanvasImageSource,\n  canvas: TCanvas,\n  {\n    x = 0,\n    y = 0,\n    width,\n    height,\n    imageSmoothingQuality,\n    alpha,\n    globalCompositeOperation,\n  }: {\n    x?: number;\n    y?: number;\n    width?: number;\n    height?: number;\n    imageSmoothingQuality?: ImageSmoothingQuality;\n    alpha?: boolean;\n    globalCompositeOperation?: GlobalCompositeOperation;\n  } = {}\n) => {\n  const imageSizes = getImageSizes(image);\n  const targetWidth = width || imageSizes.width;\n  const targetHeight = height || imageSizes.height;\n  const context = getContext(canvas, { imageSmoothingQuality, alpha, globalCompositeOperation });\n\n  context.drawImage(image, x, y, targetWidth, targetHeight);\n};\n\nconst drawAndBlurImageOnCanvas = (image, blurAmount, canvas) => {\n  const { height, width } = image;\n  const context = getContext(canvas);\n\n  context.clearRect(0, 0, width, height);\n  context.save();\n\n  context.filter = `blur(${blurAmount}px)`;\n  context.drawImage(image, 0, 0, width, height);\n\n  context.restore();\n};\n\nexport const drawAndBlurImageOnOffScreenCanvas = ({\n  canvas,\n  image,\n  blurAmount,\n}: {\n  canvas: OffscreenCanvas;\n  image: CanvasImageSource;\n  blurAmount: number;\n}) => {\n  if (blurAmount === 0) {\n    renderImageToCanvas(image, canvas);\n  } else {\n    drawAndBlurImageOnCanvas(image, blurAmount, canvas);\n  }\n};\n\nexport const drawWithCompositing = (\n  context: CanvasRenderingContext2D,\n  image: CanvasImageSource,\n  compositeOperation,\n  desiredWidth,\n  desiredHeight\n) => {\n  context.globalCompositeOperation = compositeOperation;\n\n  const { width, height } = image;\n\n  context.drawImage(\n    image,\n    0,\n    0,\n    // @ts-ignore\n    width,\n    height,\n    0,\n    0,\n    desiredWidth,\n    desiredHeight\n  );\n};\n\nexport const imageBitmapToImageData = (canvas, imageBitmap, desiredWidth, desiredHeight) => {\n  const { width, height } = imageBitmap;\n  const context = getContext(canvas);\n\n  context.drawImage(imageBitmap, 0, 0, width, height, 0, 0, desiredWidth, desiredHeight);\n\n  const imageData = context.getImageData(0, 0, desiredWidth, desiredHeight);\n\n  return imageData;\n};\n\nexport const imageToImageBitmap = ({\n  canvas,\n  image,\n}: {\n  canvas: OffscreenCanvas;\n  image: CanvasImageSource;\n}) => {\n  renderImageToCanvas(image, canvas);\n\n  return canvas.transferToImageBitmap();\n};\n","import Stats from 'stats-js';\n\nconst createFpsMeter = () => {\n  let stats;\n  let isBegined = false;\n  let isEnded = true;\n  const init = () => {\n    isBegined = false;\n    isEnded = true;\n    stats = new Stats();\n    stats.showPanel(0);\n\n    document.body.appendChild(stats.dom);\n  };\n  const begin = () => {\n    if (stats && isEnded && !isBegined) {\n      isEnded = false;\n      isBegined = true;\n      stats.begin();\n    }\n  };\n  const end = () => {\n    if (stats && isBegined && !isEnded) {\n      isEnded = true;\n      isBegined = false;\n      stats.end();\n    }\n  };\n  const reset = () => {\n    document.body.removeChild(stats.dom);\n    stats = undefined;\n  };\n\n  return { init, begin, end, reset };\n};\n\nexport default createFpsMeter;\n","const mediaStreamToVideo = (mediaStream: MediaStream): Promise<HTMLVideoElement> => {\n  const videoElement = document.createElement('video');\n\n  videoElement.srcObject = mediaStream;\n\n  return new Promise((resolve) => {\n    videoElement.onloadedmetadata = () => {\n      videoElement.width = videoElement.videoWidth;\n      videoElement.height = videoElement.videoHeight;\n      videoElement.play();\n      resolve(videoElement);\n    };\n  });\n};\n\nexport default mediaStreamToVideo;\n"],"names":["videoSource","canvas","imageMask","personMask","edgeBlurAmount","width","height","context","getContext","save","drawImage","filter","drawWithCompositing","restore","offScreenCanvases","resetOffScreenCanvases","createPersonMask","async","backgroundDarkeningMask","tensorflowBodySegmentation","segmentation","r","g","b","a","id","key","createOffScreenCanvas","ensureOffscreenCanvasCreated","renderImageDataToCanvas","transferToImageBitmap","segmenter","imageBitmap","segmentPeople","Array","isArray","length","state","setStateValue","name","value","getStateValue","getState","initState","modelSelection","createState","model","loadSegmenter","segmenterConfig","runtime","modelType","bodySegmentation","imageBitmapMask360p","imageBitmapMask720p","imageBitmapMask1080p","fpsMeter","createFpsMeter","animationRequest","AnimationRequest","requestIDBodySegmentationFrame","canvasTarget","isActive","isInProgressVideoProcessing","startVideoProcessing","canvasSource","imageBitmapMask","imageBitmapSource","imageToImageBitmap","image","init","bodySegmentationFrame","begin","end","requestAnimationFrame","targetVideoFrame","drawImageMask","then","activate","run","start","mediaStream","mediaStreamToVideo","video","createVideo","createCanvas","captureStream","stopVideoProcessing","window","cancelAnimationFrame","deactivate","reset","Promise","resolve","check","setTimeout","stop","srcObject","restart","changeParams","document","createElement","type","imageSmoothingQuality","globalCompositeOperation","alpha","desynchronized","willReadFrequently","imageSmoothingEnabled","OffscreenCanvas","getImageSizes","putImageData","renderImageToCanvas","x","y","imageSizes","targetWidth","targetHeight","compositeOperation","desiredWidth","desiredHeight","stats","isBegined","isEnded","Stats","showPanel","body","appendChild","dom","removeChild","undefined","videoElement","onloadedmetadata","videoWidth","videoHeight","play"],"sourceRoot":""}