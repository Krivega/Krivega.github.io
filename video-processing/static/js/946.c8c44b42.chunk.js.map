{"version":3,"file":"static/js/946.c8c44b42.chunk.js","mappings":"8LAEO,MAAMA,EAAe,CAACC,EAAeC,KAC1C,MAAMC,EAASC,SAASC,cAAc,UAKtC,OAHAF,EAAOF,MAAQA,EACfE,EAAOD,OAASA,EAETC,CAAP,EAGWG,EAAa,SACxBH,GAYO,IAXP,KACEI,EAAO,KADT,sBAEEC,EAFF,yBAGEC,EAHF,MAIEC,GAAQ,GAOJ,uDADF,CAAC,EAEL,MAAMC,EAAUR,EAAOG,WAAWC,EAAM,CACtCG,QACAE,gBAAgB,EAChBC,oBAAoB,IAGlBL,IACFG,EAAQG,uBAAwB,EAChCH,EAAQH,sBAAwBA,GAG9BC,IACFE,EAAQF,yBAA2BA,GAKrC,OAFwBE,CAGzB,EAEYI,EAAwB,CAACd,EAAeC,IAC3B,IAAIc,gBAAgBf,EAAOC,GA2B/Ce,EAAiBC,IACrB,MAAM,OAAEhB,EAAF,MAAUD,GAAUiB,EAE1B,MAAO,CAAEhB,SAAQD,QAAjB,EAGWkB,EAA0B,CAACD,EAAkBf,KACxCG,EAAWH,GAEnBiB,aAAaF,EAAO,EAAG,EAA/B,EAGWG,EAAsB,SACjCH,EACAf,GAkBI,IAjBJ,EACEmB,EAAI,EADN,EAEEC,EAAI,EAFN,MAGEtB,EAHF,OAIEC,EAJF,sBAKEM,EALF,MAMEE,EANF,yBAOED,GAUC,uDADC,CAAC,EAEL,MAAMe,EAAaP,EAAcC,GAC3BO,EAAcxB,GAASuB,EAAWvB,MAClCyB,EAAexB,GAAUsB,EAAWtB,OACpCS,EAAUL,EAAWH,EAAQ,CAAEK,wBAAuBE,QAAOD,6BAEnEE,EAAQgB,UAAUT,EAAOI,EAAGC,EAAGE,EAAaC,EAC7C,EA+BYE,EAAsB,CACjCjB,EACAO,EACAW,EACAC,EACAC,KAEApB,EAAQF,yBAA2BoB,EAEnC,MAAM,MAAE5B,EAAF,OAASC,GAAWgB,EAE1BP,EAAQgB,UACNT,EACA,EACA,EAEAjB,EACAC,EACA,EACA,EACA4B,EACAC,EAVF,EAyBWC,EAAqB,IAM3B,IAN4B,OACjC7B,EADiC,MAEjCe,GAII,EAGJ,OAFAG,EAAoBH,EAAOf,GAEpBA,EAAO8B,uBAAd,C,sEC1LF,MAoCA,EApCuB,KACrB,IAAIC,EACAC,GAAW,EACXC,GAAU,EA8Bd,MAAO,CAAEC,KA7BI,KACXF,GAAW,EACXC,GAAU,EACVF,EAAQ,IAAII,KACZJ,EAAMK,UAAU,GAEZC,OAAOC,OAAOxC,MAAQ,KACxBG,SAASsC,KAAKC,YAAYT,EAAMU,IACjC,EAqBYC,MAnBD,KACRX,GAASE,IAAYD,IACvBC,GAAU,EACVD,GAAW,EACXD,EAAMW,QACP,EAcmBC,IAZV,KACNZ,GAASC,IAAaC,IACxBA,GAAU,EACVD,GAAW,EACXD,EAAMY,MACP,EAOwBC,MALb,KACZ3C,SAASsC,KAAKM,YAAYd,EAAMU,KAChCV,OAAQe,CAAR,EAGF,C,+CCnCF,MAeA,EAf4BC,IAC1B,MAAMC,EAAe/C,SAASC,cAAc,SAI5C,OAFA8C,EAAaC,UAAYF,EAElB,IAAIG,SAASC,IAClBH,EAAaI,iBAAmB,KAC9BJ,EAAalD,MAAQkD,EAAaK,WAClCL,EAAajD,OAASiD,EAAaM,YACnCN,EAAaO,OACbJ,EAAQH,EAAR,CAJF,GADF,C,wGCFF,MAuCA,EAvCsB,IAYf,IAZgB,YACrBQ,EADqB,OAErBxD,EAFqB,UAGrByD,EAHqB,WAIrBC,EAJqB,eAKrBC,GAOI,EACJ,MAAM,MAAE7D,EAAF,OAASC,GAAWyD,EACpBhD,GAAUL,EAAAA,EAAAA,IAAWH,GAEtB0D,GAMLlD,EAAQoD,OAGRpD,EAAQgB,UAAUgC,EAAa,EAAG,GAE9BG,EAAiB,IACnBnD,EAAQqD,OAAU,QAAOF,SAG3BlC,EAAAA,EAAAA,IAAoBjB,EAASkD,EAAY,kBAAmB5D,EAAOC,GACnES,EAAQqD,OAAS,QAEjBpC,EAAAA,EAAAA,IAAoBjB,EAASiD,EAAW,mBAAoB3D,EAAOC,GAEnES,EAAQsD,WAnBNtD,EAAQgB,UAAUgC,EAAa,EAAG,EAmBpC,E,oCCnCF,IAAIO,EAAoB,CAAC,EAElB,MAAMC,EAAyB,KACpCD,EAAoB,CAAC,CAArB,EAaWE,EAAmBC,UAC9B,MAKMC,QAAgCC,EAAAA,GACpCC,EANsB,CAAEC,EAAG,EAAGC,EAAG,EAAGC,EAAG,EAAGC,EAAG,GACvB,CAAEH,EAAG,EAAGC,EAAG,EAAGC,EAAG,EAAGC,EAAG,MAC3B,EACQ,KAUtB,MAAE3E,EAAF,OAASC,GAAWoE,EACpBnE,EAzB6B,EAAC0E,EAAI5E,EAAOC,KAC/C,MAAM4E,EAAO,GAAED,KAAM5E,KAASC,IAM9B,OAJKgE,EAAkBY,KACrBZ,EAAkBY,IAAO/D,EAAAA,EAAAA,IAAsBd,EAAOC,IAGjDgE,EAAkBY,EAAzB,EAkBeC,CAA6B,cAAe9E,EAAOC,GAIlE,OAFAiB,EAAAA,EAAAA,IAAwBmD,EAAyBnE,GAE1CA,EAAO8B,uBAAd,ECxBF,EAZyBoC,MAAOW,EAAP,KAAsD,IAArB,YAAEC,GAAkB,EAC5E,MAAMT,QAAqBQ,EAAUE,cAAcD,GAEnD,GAAIE,MAAMC,QAAQZ,IAAyC,IAAxBA,EAAaa,OAC9C,OAKF,OAFmBjB,EAAiBI,EAEpC,ECmBF,EAzBoB,KAClB,MAAMc,EAAgB,CAAC,EAQjBC,EAAgB,CAACC,EAAcC,KACnCH,EAAME,GAAQC,CAAd,EAOF,MAAO,CACLC,cAZqBF,GACdF,EAAME,GAYbG,SAhBe,IACRL,EAgBPC,gBACAK,UARgB,IAAiC,IAAhC,eAAEC,GAA6B,EAChDN,EAAc,iBAAkBM,EAAhC,EAGF,GCZI,SAAEF,EAAF,UAAYC,EAAZ,cAAuBL,GAAkBO,IAC/C,IAAId,EAEJ,MAAMe,EAAQxB,EAAAA,GAAAA,4BAERyB,EAAgB3B,UAAoE,IAA7D,eAAEwB,GAA0D,EACvF,MAAMI,EAAkB,CACtBC,QAAS,OACTC,UAAWN,GAGbb,QAAkBT,EAAAA,GAA2CwB,EAAOE,EAApE,EA0BF,EAvBa,IAA8D,IAA7D,eAAEJ,GAA0D,EAMxE,OALAD,EAAU,CACRC,mBAEF1B,IAEO6B,EAAc,CAAEH,kBAAvB,EAiBF,EAdsBZ,GACbmB,EAAiBpB,EAAW,CACjCC,gBAYJ,EARqB,IAA8D,IAA7D,eAAEY,GAA0D,EAKhF,OAJAN,EAAc,iBAAkBM,GAEhC1B,IAEO6B,EAAc,CAAEH,kBAAvB,EC4JF,EA7L4D,IAIrD,IAJsD,oBAC3DQ,EAD2D,oBAE3DC,EAF2D,qBAG3DC,GACI,EACJ,MAYMC,GAAWC,EAAAA,EAAAA,KACXC,EAAmB,IAAIC,EAAAA,EAC7B,IACIC,EACAjD,EACAkD,EAHAC,GAAW,EAYf,IAAIC,GAA8B,EAClC,MAaMC,EAAuB,IAMtB,IANuB,eAC5BlD,EAD4B,iBAE5BmD,GAII,EACJ,MAAM,MAAEhH,EAAF,OAASC,GAAWyD,EACpBuD,GAAenG,EAAAA,EAAAA,IAAsBd,EAAOC,GAC5CiH,EAjDuBlH,KAE7B,OAAQA,GACN,KAAK,IACH,OAAOoG,EACT,KAAK,KACH,OAAOC,EAGX,OAAOC,CAAP,EAwCwBa,CAAsBnH,GAE9C,IACI4D,EADAwD,GAAoBrF,EAAAA,EAAAA,IAAmB,CAAEd,MAAOyC,EAAaxD,OAAQ+G,IAGzEV,EAASnE,OACTyE,GAAW,EAEX,MAAMQ,EAAwBjD,UAE5BmC,EAAS3D,QACTkE,GAA8B,EAE1BD,IACFjD,QAAmBqC,EAAqBmB,IAI1Cb,EAAS1D,MAETiE,GAA8B,EAG1BD,IACFF,EAAiCW,sBAAsBD,GACxD,EAGGE,EAAmB,KACvBH,GAAoBrF,EAAAA,EAAAA,IAAmB,CAAEd,MAAOyC,EAAaxD,OAAQ+G,IAErEO,EAAc,CACZ5D,aACAC,iBACAH,cACAC,UAAWuD,EACXhH,OAAQ0G,GALV,EASFS,IAAwBI,MAAK,KAC3BhB,EAAiBiB,WACjBjB,EAAiBkB,IAAIJ,EAAkB,GAAvC,GAFF,EAMIK,EAAQ,IAUP,IAVQ,YACb3E,EADa,eAEb2C,EAFa,eAGb/B,EAHa,iBAIbmD,GAMI,EACJ,OAAOf,EACC,CACJL,mBAED6B,MAAK,IA3FWxE,KACZ4E,EAAAA,EAAAA,GAAmB5E,GAAawE,MAAMK,IAC3CpE,EAAcoE,EAEPpE,KAwFEqE,CAAY9E,KAEpBwE,MAAK,KACJ,MAAM,MAAEzH,EAAF,OAASC,GAAWyD,EAE1BkD,GAAe7G,EAAAA,EAAAA,IAAaC,EAAOC,GAEnC8G,EAAqB,CAAElD,iBAAgBmD,qBAIvC,OAF0BJ,EAAaoB,eAEvC,GAhBJ,EAmBIC,EAAsB,KAC1BpB,GAAW,EACXtE,OAAO2F,qBAAqBvB,GAC5BF,EAAiB0B,aACjB5B,EAASzD,QArGF,IAAIM,SAAeC,IACxB,MAAM+E,EAAQ,MACwB,IAAhCtB,EACFzD,IAEAgF,WAAWD,EAAO,IACnB,EAGHA,GAAO,KAgGLE,EAAO,IACJL,IAAsBR,MAAK,KAC5B/D,IACFA,EAAYP,UAAY,KACzB,IA4CL,OAAOC,QAAQC,QAAQ,CAAEuE,QAAOW,QArBhB,IAUT,IAVU,YACftF,EADe,eAEf2C,EAFe,iBAGfoB,EAHe,eAIfnD,GAMI,EACJ,OAAOyE,IAAOb,MAAK,IACVG,EAAM,CACX3E,cACA2C,iBACA/B,iBACAmD,sBALJ,EAUuCwB,aAxCpB,IAQd,IARe,eACpB5C,EADoB,eAEpB/B,EAFoB,iBAGpBmD,GAKI,EACJ,OAAOiB,IACJR,MAAK,IACGxB,EAAqB,CAC1BL,qBAGH6B,MAAK,IACGV,EAAqB,CAAElD,iBAAgBmD,sBAPlD,EA+BqDsB,QAAvD,C","sources":["../../../utils/src/canvas.ts","../../../utils/src/createFpsMeter.ts","../../../utils/src/mediaStreamToVideo.ts","../../../video-processor/src/VideoProcessors/TensorFlow/drawImageMask.ts","../../../video-processor/src/VideoProcessors/TensorFlow/runtime/render.ts","../../../video-processor/src/VideoProcessors/TensorFlow/runtime/bodySegmentation.ts","../../../video-processor/src/VideoProcessors/TensorFlow/runtime/state.ts","../../../video-processor/src/VideoProcessors/TensorFlow/runtime/index.ts","../../../video-processor/src/VideoProcessors/TensorFlow/index.ts"],"sourcesContent":["export type TCanvas = HTMLCanvasElement | OffscreenCanvas;\n\nexport const createCanvas = (width: number, height: number): HTMLCanvasElement => {\n  const canvas = document.createElement('canvas');\n\n  canvas.width = width;\n  canvas.height = height;\n\n  return canvas;\n};\n\nexport const getContext = <T = CanvasRenderingContext2D>(\n  canvas: TCanvas,\n  {\n    type = '2d',\n    imageSmoothingQuality,\n    globalCompositeOperation,\n    alpha = false,\n  }: {\n    type?: '2d';\n    imageSmoothingQuality?: ImageSmoothingQuality;\n    globalCompositeOperation?: GlobalCompositeOperation;\n    alpha?: boolean;\n  } = {}\n): T => {\n  const context = canvas.getContext(type, {\n    alpha,\n    desynchronized: true,\n    willReadFrequently: true,\n  }) as CanvasRenderingContext2D;\n\n  if (imageSmoothingQuality) {\n    context.imageSmoothingEnabled = true;\n    context.imageSmoothingQuality = imageSmoothingQuality;\n  }\n\n  if (globalCompositeOperation) {\n    context.globalCompositeOperation = globalCompositeOperation;\n  }\n\n  const contextReturned = context as unknown as T;\n\n  return contextReturned;\n};\n\nexport const createOffScreenCanvas = (width: number, height: number): OffscreenCanvas => {\n  const offScreenCanvas = new OffscreenCanvas(width, height);\n\n  return offScreenCanvas;\n};\n\nexport const fill = (\n  canvas: TCanvas,\n  {\n    x = 0,\n    y = 0,\n    width,\n    height,\n    color = '#202020',\n  }: {\n    x?: number;\n    y?: number;\n    width: number;\n    height: number;\n    color?: string;\n  }\n) => {\n  const context = getContext(canvas);\n\n  context.fillStyle = color;\n  context.fillRect(x, y, width, height);\n};\n\nconst getImageSizes = (image: CanvasImageSource | ImageBitmap) => {\n  const { height, width } = image as { width: number; height: number };\n\n  return { height, width };\n};\n\nexport const renderImageDataToCanvas = (image: ImageData, canvas) => {\n  const context = getContext(canvas);\n\n  context.putImageData(image, 0, 0);\n};\n\nexport const renderImageToCanvas = (\n  image: CanvasImageSource,\n  canvas: TCanvas,\n  {\n    x = 0,\n    y = 0,\n    width,\n    height,\n    imageSmoothingQuality,\n    alpha,\n    globalCompositeOperation,\n  }: {\n    x?: number;\n    y?: number;\n    width?: number;\n    height?: number;\n    imageSmoothingQuality?: ImageSmoothingQuality;\n    alpha?: boolean;\n    globalCompositeOperation?: GlobalCompositeOperation;\n  } = {}\n) => {\n  const imageSizes = getImageSizes(image);\n  const targetWidth = width || imageSizes.width;\n  const targetHeight = height || imageSizes.height;\n  const context = getContext(canvas, { imageSmoothingQuality, alpha, globalCompositeOperation });\n\n  context.drawImage(image, x, y, targetWidth, targetHeight);\n};\n\nconst drawAndBlurImageOnCanvas = (image, blurAmount, canvas) => {\n  const { height, width } = image;\n  const context = getContext(canvas);\n\n  context.clearRect(0, 0, width, height);\n  context.save();\n\n  context.filter = `blur(${blurAmount}px)`;\n  context.drawImage(image, 0, 0, width, height);\n\n  context.restore();\n};\n\nexport const drawAndBlurImageOnOffScreenCanvas = ({\n  canvas,\n  image,\n  blurAmount,\n}: {\n  canvas: OffscreenCanvas;\n  image: CanvasImageSource;\n  blurAmount: number;\n}) => {\n  if (blurAmount === 0) {\n    renderImageToCanvas(image, canvas);\n  } else {\n    drawAndBlurImageOnCanvas(image, blurAmount, canvas);\n  }\n};\n\nexport const drawWithCompositing = (\n  context: CanvasRenderingContext2D,\n  image: CanvasImageSource,\n  compositeOperation,\n  desiredWidth,\n  desiredHeight\n) => {\n  context.globalCompositeOperation = compositeOperation;\n\n  const { width, height } = image;\n\n  context.drawImage(\n    image,\n    0,\n    0,\n    // @ts-ignore\n    width,\n    height,\n    0,\n    0,\n    desiredWidth,\n    desiredHeight\n  );\n};\n\nexport const imageBitmapToImageData = (canvas, imageBitmap, desiredWidth, desiredHeight) => {\n  const { width, height } = imageBitmap;\n  const context = getContext(canvas);\n\n  context.drawImage(imageBitmap, 0, 0, width, height, 0, 0, desiredWidth, desiredHeight);\n\n  const imageData = context.getImageData(0, 0, desiredWidth, desiredHeight);\n\n  return imageData;\n};\n\nexport const imageToImageBitmap = ({\n  canvas,\n  image,\n}: {\n  canvas: OffscreenCanvas;\n  image: CanvasImageSource;\n}) => {\n  renderImageToCanvas(image, canvas);\n\n  return canvas.transferToImageBitmap();\n};\n","import Stats from 'stats-js';\n\nconst createFpsMeter = () => {\n  let stats;\n  let isBegins = false;\n  let isEnded = true;\n  const init = () => {\n    isBegins = false;\n    isEnded = true;\n    stats = new Stats();\n    stats.showPanel(0);\n\n    if (window.screen.width > 500) {\n      document.body.appendChild(stats.dom);\n    }\n  };\n  const begin = () => {\n    if (stats && isEnded && !isBegins) {\n      isEnded = false;\n      isBegins = true;\n      stats.begin();\n    }\n  };\n  const end = () => {\n    if (stats && isBegins && !isEnded) {\n      isEnded = true;\n      isBegins = false;\n      stats.end();\n    }\n  };\n  const reset = () => {\n    document.body.removeChild(stats.dom);\n    stats = undefined;\n  };\n\n  return { init, begin, end, reset };\n};\n\nexport default createFpsMeter;\n","const mediaStreamToVideo = (mediaStream: MediaStream): Promise<HTMLVideoElement> => {\n  const videoElement = document.createElement('video');\n\n  videoElement.srcObject = mediaStream;\n\n  return new Promise((resolve) => {\n    videoElement.onloadedmetadata = () => {\n      videoElement.width = videoElement.videoWidth;\n      videoElement.height = videoElement.videoHeight;\n      videoElement.play();\n      resolve(videoElement);\n    };\n  });\n};\n\nexport default mediaStreamToVideo;\n","import { getContext, drawWithCompositing } from '@experiments/utils/src/canvas';\nimport type { TCanvas } from '@experiments/utils/src/canvas';\n\nconst drawImageMask = ({\n  videoSource,\n  canvas,\n  imageMask,\n  personMask,\n  edgeBlurAmount,\n}: {\n  videoSource: HTMLVideoElement;\n  canvas: TCanvas;\n  imageMask: HTMLImageElement;\n  personMask?: ImageBitmap;\n  edgeBlurAmount: number;\n}) => {\n  const { width, height } = videoSource;\n  const context = getContext(canvas);\n\n  if (!personMask) {\n    context.drawImage(videoSource, 0, 0);\n\n    return;\n  }\n\n  context.save();\n\n  // render original image\n  context.drawImage(videoSource, 0, 0);\n\n  if (edgeBlurAmount > 0) {\n    context.filter = `blur(${edgeBlurAmount}px)`;\n  }\n\n  drawWithCompositing(context, personMask, 'destination-out', width, height);\n  context.filter = 'none';\n\n  drawWithCompositing(context, imageMask, 'destination-over', width, height);\n\n  context.restore();\n};\n\nexport default drawImageMask;\n","import * as tensorflowBodySegmentation from '@tensorflow-models/body-segmentation';\nimport type { Segmentation } from '@tensorflow-models/body-segmentation/dist/shared/calculators/interfaces/common_interfaces';\nimport { renderImageDataToCanvas, createOffScreenCanvas } from '@experiments/utils/src/canvas';\n\nlet offScreenCanvases = {};\n\nexport const resetOffScreenCanvases = () => {\n  offScreenCanvases = {};\n};\n\nconst ensureOffscreenCanvasCreated = (id, width, height) => {\n  const key = `${id}_${width}_${height}`;\n\n  if (!offScreenCanvases[key]) {\n    offScreenCanvases[key] = createOffScreenCanvas(width, height);\n  }\n\n  return offScreenCanvases[key];\n};\n\nexport const createPersonMask = async (segmentation: Segmentation[]) => {\n  const foregroundColor = { r: 0, g: 0, b: 0, a: 0 };\n  const backgroundColor = { r: 0, g: 0, b: 0, a: 255 };\n  const drawContour = true;\n  const foregroundThreshold = 0.6;\n\n  const backgroundDarkeningMask = await tensorflowBodySegmentation.toBinaryMask(\n    segmentation,\n    foregroundColor,\n    backgroundColor,\n    drawContour,\n    foregroundThreshold\n  );\n\n  const { width, height } = backgroundDarkeningMask;\n  const canvas = ensureOffscreenCanvasCreated('blurredMask', width, height);\n\n  renderImageDataToCanvas(backgroundDarkeningMask, canvas);\n\n  return canvas.transferToImageBitmap();\n};\n","import type { BodySegmenter } from '@tensorflow-models/body-segmentation/dist/body_segmenter';\nimport { createPersonMask } from './render';\n\nconst bodySegmentation = async (segmenter: BodySegmenter, { imageBitmap }) => {\n  const segmentation = await segmenter.segmentPeople(imageBitmap);\n\n  if (Array.isArray(segmentation) && segmentation.length === 0) {\n    return undefined;\n  }\n\n  const personMask = createPersonMask(segmentation);\n\n  return personMask;\n};\n\nexport default bodySegmentation;\n","import type { TModelSelection } from '../../../typings';\n\ntype TState = {\n  modelSelection?: TModelSelection;\n};\n\nconst createState = () => {\n  const state: TState = {};\n\n  const getState = (): TState => {\n    return state;\n  };\n  const getStateValue = (name: string): string | undefined => {\n    return state[name];\n  };\n  const setStateValue = (name: string, value?: string) => {\n    state[name] = value;\n  };\n\n  const initState = ({ modelSelection }: TState) => {\n    setStateValue('modelSelection', modelSelection);\n  };\n\n  return {\n    getStateValue,\n    getState,\n    setStateValue,\n    initState,\n  };\n};\n\nexport default createState;\n","import '@tensorflow/tfjs-core';\nimport '@tensorflow/tfjs-backend-webgl';\nimport * as tensorflowBodySegmentation from '@tensorflow-models/body-segmentation';\nimport type { BodySegmenter } from '@tensorflow-models/body-segmentation/dist/body_segmenter';\nimport '@tensorflow/tfjs-converter';\nimport type { TModelSelection } from '../../../typings';\n// import '@mediapipe/selfie_segmentation';\nimport { resetOffScreenCanvases } from './render';\nimport bodySegmentation from './bodySegmentation';\nimport createState from './state';\n\nconst { getState, initState, setStateValue } = createState();\nlet segmenter: BodySegmenter;\n\nconst model = tensorflowBodySegmentation.SupportedModels.MediaPipeSelfieSegmentation; // or 'BodyPix'|| MediaPipeSelfieSegmentation\n\nconst loadSegmenter = async ({ modelSelection }: { modelSelection: TModelSelection }) => {\n  const segmenterConfig = {\n    runtime: 'tfjs' as const, // or 'tfjs' mediapipe\n    modelType: modelSelection, // or 'landscape'\n  };\n\n  segmenter = await tensorflowBodySegmentation.createSegmenter(model, segmenterConfig);\n};\n\nconst init = ({ modelSelection }: { modelSelection: TModelSelection }) => {\n  initState({\n    modelSelection,\n  });\n  resetOffScreenCanvases();\n\n  return loadSegmenter({ modelSelection });\n};\n\nconst processVideo = (imageBitmap) => {\n  return bodySegmentation(segmenter, {\n    imageBitmap,\n  });\n};\n\nconst changeParams = ({ modelSelection }: { modelSelection: TModelSelection }) => {\n  setStateValue('modelSelection', modelSelection);\n\n  resetOffScreenCanvases();\n\n  return loadSegmenter({ modelSelection });\n};\n\nexport default { init, processVideo, changeParams };\n","import AnimationRequest from 'request-animation-runner';\nimport createFpsMeter from '@experiments/utils/src/createFpsMeter';\nimport mediaStreamToVideo from '@experiments/utils/src/mediaStreamToVideo';\nimport {\n  createCanvas,\n  createOffScreenCanvas,\n  imageToImageBitmap,\n} from '@experiments/utils/src/canvas';\nimport type { TResolveProcessVideo, TModelSelection } from '../../typings';\nimport drawImageMask from './drawImageMask';\nimport runtime from './runtime';\n\nconst resolveProcessVideoTensorFlow: TResolveProcessVideo = ({\n  imageBitmapMask360p,\n  imageBitmapMask720p,\n  imageBitmapMask1080p,\n}) => {\n  const getImageBitmapByWidth = (width: number): HTMLImageElement => {\n    // eslint-disable-next-line default-case\n    switch (width) {\n      case 640:\n        return imageBitmapMask360p;\n      case 1280:\n        return imageBitmapMask720p;\n    }\n\n    return imageBitmapMask1080p;\n  };\n\n  const fpsMeter = createFpsMeter();\n  const animationRequest = new AnimationRequest();\n  let isActive = false;\n  let requestIDBodySegmentationFrame: number;\n  let videoSource: HTMLVideoElement;\n  let canvasTarget: HTMLCanvasElement;\n\n  const createVideo = (mediaStream: MediaStream) => {\n    return mediaStreamToVideo(mediaStream).then((video) => {\n      videoSource = video;\n\n      return videoSource;\n    });\n  };\n  let isInProgressVideoProcessing = false;\n  const checkEndProgressVideoProcessing = () => {\n    return new Promise<void>((resolve) => {\n      const check = () => {\n        if (isInProgressVideoProcessing === false) {\n          resolve();\n        } else {\n          setTimeout(check, 100);\n        }\n      };\n\n      check();\n    });\n  };\n  const startVideoProcessing = ({\n    edgeBlurAmount,\n    isBlurBackground,\n  }: {\n    edgeBlurAmount: number;\n    isBlurBackground: boolean;\n  }) => {\n    const { width, height } = videoSource;\n    const canvasSource = createOffScreenCanvas(width, height);\n    const imageBitmapMask = getImageBitmapByWidth(width);\n\n    let imageBitmapSource = imageToImageBitmap({ image: videoSource, canvas: canvasSource });\n    let personMask: ImageBitmap;\n\n    fpsMeter.init();\n    isActive = true;\n\n    const bodySegmentationFrame = async () => {\n      // Begin monitoring code for frames per second\n      fpsMeter.begin();\n      isInProgressVideoProcessing = true;\n\n      if (isActive) {\n        personMask = await runtime.processVideo(imageBitmapSource);\n      }\n\n      // End monitoring code for frames per second\n      fpsMeter.end();\n\n      isInProgressVideoProcessing = false;\n\n      // for check after async\n      if (isActive) {\n        requestIDBodySegmentationFrame = requestAnimationFrame(bodySegmentationFrame);\n      }\n    };\n\n    const targetVideoFrame = () => {\n      imageBitmapSource = imageToImageBitmap({ image: videoSource, canvas: canvasSource });\n\n      drawImageMask({\n        personMask,\n        edgeBlurAmount,\n        videoSource,\n        imageMask: imageBitmapMask,\n        canvas: canvasTarget,\n      });\n    };\n\n    bodySegmentationFrame().then(() => {\n      animationRequest.activate();\n      animationRequest.run(targetVideoFrame, 24);\n    });\n  };\n\n  const start = ({\n    mediaStream,\n    modelSelection,\n    edgeBlurAmount,\n    isBlurBackground,\n  }: {\n    mediaStream: MediaStream;\n    modelSelection: TModelSelection;\n    edgeBlurAmount: number;\n    isBlurBackground: boolean;\n  }) => {\n    return runtime\n      .init({\n        modelSelection,\n      })\n      .then(() => {\n        return createVideo(mediaStream);\n      })\n      .then(() => {\n        const { width, height } = videoSource;\n\n        canvasTarget = createCanvas(width, height);\n\n        startVideoProcessing({ edgeBlurAmount, isBlurBackground });\n\n        const mediaStreamOutput = canvasTarget.captureStream();\n\n        return mediaStreamOutput;\n      });\n  };\n  const stopVideoProcessing = () => {\n    isActive = false;\n    window.cancelAnimationFrame(requestIDBodySegmentationFrame);\n    animationRequest.deactivate();\n    fpsMeter.reset();\n\n    return checkEndProgressVideoProcessing();\n  };\n  const stop = () => {\n    return stopVideoProcessing().then(() => {\n      if (videoSource) {\n        videoSource.srcObject = null;\n      }\n    });\n  };\n\n  const changeParams = ({\n    modelSelection,\n    edgeBlurAmount,\n    isBlurBackground,\n  }: {\n    modelSelection: TModelSelection;\n    edgeBlurAmount: number;\n    isBlurBackground: boolean;\n  }) => {\n    return stopVideoProcessing()\n      .then(() => {\n        return runtime.changeParams({\n          modelSelection,\n        });\n      })\n      .then(() => {\n        return startVideoProcessing({ edgeBlurAmount, isBlurBackground });\n      });\n  };\n  const restart = ({\n    mediaStream,\n    modelSelection,\n    isBlurBackground,\n    edgeBlurAmount,\n  }: {\n    mediaStream: MediaStream;\n    modelSelection: TModelSelection;\n    edgeBlurAmount: number;\n    isBlurBackground: boolean;\n  }) => {\n    return stop().then(() => {\n      return start({\n        mediaStream,\n        modelSelection,\n        edgeBlurAmount,\n        isBlurBackground,\n      });\n    });\n  };\n\n  return Promise.resolve({ start, restart, changeParams, stop });\n};\n\nexport default resolveProcessVideoTensorFlow;\n"],"names":["createCanvas","width","height","canvas","document","createElement","getContext","type","imageSmoothingQuality","globalCompositeOperation","alpha","context","desynchronized","willReadFrequently","imageSmoothingEnabled","createOffScreenCanvas","OffscreenCanvas","getImageSizes","image","renderImageDataToCanvas","putImageData","renderImageToCanvas","x","y","imageSizes","targetWidth","targetHeight","drawImage","drawWithCompositing","compositeOperation","desiredWidth","desiredHeight","imageToImageBitmap","transferToImageBitmap","stats","isBegins","isEnded","init","Stats","showPanel","window","screen","body","appendChild","dom","begin","end","reset","removeChild","undefined","mediaStream","videoElement","srcObject","Promise","resolve","onloadedmetadata","videoWidth","videoHeight","play","videoSource","imageMask","personMask","edgeBlurAmount","save","filter","restore","offScreenCanvases","resetOffScreenCanvases","createPersonMask","async","backgroundDarkeningMask","tensorflowBodySegmentation","segmentation","r","g","b","a","id","key","ensureOffscreenCanvasCreated","segmenter","imageBitmap","segmentPeople","Array","isArray","length","state","setStateValue","name","value","getStateValue","getState","initState","modelSelection","createState","model","loadSegmenter","segmenterConfig","runtime","modelType","bodySegmentation","imageBitmapMask360p","imageBitmapMask720p","imageBitmapMask1080p","fpsMeter","createFpsMeter","animationRequest","AnimationRequest","requestIDBodySegmentationFrame","canvasTarget","isActive","isInProgressVideoProcessing","startVideoProcessing","isBlurBackground","canvasSource","imageBitmapMask","getImageBitmapByWidth","imageBitmapSource","bodySegmentationFrame","requestAnimationFrame","targetVideoFrame","drawImageMask","then","activate","run","start","mediaStreamToVideo","video","createVideo","captureStream","stopVideoProcessing","cancelAnimationFrame","deactivate","check","setTimeout","stop","restart","changeParams"],"sourceRoot":""}